{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfiltration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CN_correction\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m design_storms, effective_storms\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munithydrographs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SynthUnitHydro\n",
      "File \u001b[1;32mc:\\home\\lucas\\P-projects\\geobasins\\src\\__init__.py:11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m # @ Author: Lucas Glasner (lgvivanco96@gmail.com)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m # @ Create Time: 1969-12-31 21:00:00\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m # @ Dependencies:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m '''\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m misc\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geomorphology\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unithydrographs\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infiltration\n",
      "File \u001b[1;32mc:\\home\\lucas\\P-projects\\geobasins\\src\\geomorphology.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "File \u001b[1;32mc:\\lucas\\miniconda3\\envs\\gis\\Lib\\site-packages\\networkx\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generators\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m readwrite\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreadwrite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Need to test with SciPy, when available\u001b[39;00m\n",
      "File \u001b[1;32mc:\\lucas\\miniconda3\\envs\\gis\\Lib\\site-packages\\networkx\\readwrite\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreadwrite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreadwrite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreadwrite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgexf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreadwrite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreadwrite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1186\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "* @ Author: Lucas Glasner (lgvivanco96@gmail.com)\n",
    "* @ Create Time: 1969-12-31 21:00:00\n",
    "* @ Modified by: Lucas Glasner,\n",
    "* @ Modified time: 2024-01-19 15:43:04\n",
    "* @ Description:\n",
    "        Routines for the design of  flood hydrographs based on synthetic\n",
    "        hyetographs and unit hydrograph (SUH) methods.\n",
    "* @ Dependencies:\n",
    "*/\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal as sg\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "from src.infiltration import CN_correction\n",
    "from src.rain import design_storms, effective_storms\n",
    "from src.unithydrographs import SynthUnitHydro\n",
    "from src.misc import to_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- main routines ------------------------------ #\n",
    "def parse_params(params_path, SHyeto_path, tstep=0.1):\n",
    "    \"\"\"\n",
    "    Load input data and preprocess for the model run\n",
    "\n",
    "    Args:\n",
    "        params_path (str): Path to textfile with basin parameters. \n",
    "        SHyeto_path (str): Path to textfile with synthetic storm data-\n",
    "        tstep (float, optional): Define simulation timestep. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        (tuple): formatted parameters,\n",
    "                 daily rainfall, \n",
    "                 synthetic hyetographs,\n",
    "                 timestep\n",
    "    \"\"\"    \n",
    "    file_ext = params_path.split('.')[-1]\n",
    "    if (file_ext == 'csv') or (file_ext == 'txt'):\n",
    "        params = pd.read_csv(params_path, index_col=0)\n",
    "    elif (file_ext == 'xlsx') or (file_ext == 'xls'):\n",
    "        params = pd.read_excel(params_path, index_col=0)\n",
    "    else:\n",
    "        raise ValueError('Parameter extension file must be \".xlsx\" or \".csv\"')\n",
    "    params = params.map(lambda x: to_numeric(x))\n",
    "    \n",
    "    # Prepare basin parameters\n",
    "    # params.loc['final_curvenumber_1'] = [CN_correction(cn, amc)\n",
    "    #                                     for cn, amc in zip(\n",
    "    #                                         params.loc['curvenumber_1'],\n",
    "    #                                         params.loc['moisturecondition_1'])]\n",
    "    basin_params = params.loc[['name','area_km2', 'mriverlen_km',\n",
    "                               'out2centroidlen_km', 'meanslope_1',\n",
    "                               'hmax_m', 'hmin_m', 'SUnitHydro',\n",
    "                               'curvenumber_1', 'moisturecondition_1']]\n",
    "    cns = params.index.map(lambda index: 'fCN' in index)\n",
    "    cns = params.loc[cns]\n",
    "    basin_params = pd.concat([basin_params, cns], axis=0)\n",
    "\n",
    "\n",
    "    # Prepare storm parameters\n",
    "    pr_mm24hr = params[params.index.map(lambda x: 'pr' in x)]\n",
    "    return_periods = pr_mm24hr.index.map(\n",
    "        lambda x: int(x.split('_')[1].replace('T', '')))\n",
    "    pr_mm24hr.index = return_periods\n",
    "    params.loc['SHyeto'] = params.loc['SHyeto'].map(lambda x: x.split(';'))\n",
    "    synth_hyeto = pd.read_csv(SHyeto_path, index_col=0)\n",
    "    storm_params = {key:{'storm_durations':[4,6,12,18,24,30,36,42,48,60,72],\n",
    "                         'synth_hyeto':synth_hyeto[params[key].loc['SHyeto']],\n",
    "                         'rainfall':pr_mm24hr[key].dropna()}\n",
    "                    for key in params.columns}\n",
    "\n",
    "    return basin_params, storm_params, tstep\n",
    "\n",
    "def BasinFloodHydrograph(timestep, basin_params, storm_params):\n",
    "    \"\"\"\n",
    "    Main routine to compute a basin flood hydrograph from a set of \n",
    "    basin and storm parameters.\n",
    "\n",
    "    Args:\n",
    "        timestep (float): Simulation timestep in hours\n",
    "        basin_params (dict): Basin parameters and geomorpholical properties.\n",
    "        storm_params (dict): Storm parameters\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    # Compute Unit Hydrograph\n",
    "    UH    = SynthUnitHydro(method=basin_params['SUnitHydro'],\n",
    "                           basin_params=basin_params,\n",
    "                           timestep=timestep)\n",
    "    uh, uh_params = UH.compute()\n",
    "    uhname        = uh.name.split('_')[0]\n",
    "    tstep         = UH.timestep\n",
    "    uh = uh.to_xarray().rename({'index':'time'})\n",
    "    # uh = uh.reindex({'time':dhyeto.time})\n",
    "    uh.attrs = {'standard_name':f'{uhname} unit hydrograph',\n",
    "                'units':uh.name.split('_')[1],\n",
    "                'qpeak':uh_params.qpeak.round(2),\n",
    "                'tpeak':uh_params.tpeak.round(2),\n",
    "                'tbase':uh_params.tbase.round(2),\n",
    "                'tstep':uh_params.tstep.round(2)}\n",
    "    uh.name = 'UnitHydro'\n",
    "    \n",
    "    # Compute design storms\n",
    "    dhyeto  = design_storms(storm_duration=storm_params['storm_durations'],\n",
    "                            synth_hyeto=storm_params['synth_hyeto'],\n",
    "                            tstep=tstep,\n",
    "                            precips=storm_params['rainfall']).astype(float)\n",
    "    \n",
    "    # dhyeto = effective_storms(dhyeto.pr, method='SCS',\n",
    "    #                           CN=CN_correction(basin_params['curvenumber_1'],\n",
    "    #                                            basin_params['moisturecondition_1']))\n",
    "    cns   = basin_params.loc[basin_params.index.map(lambda index: 'fCN' in index)]\n",
    "    farea = cns.values\n",
    "    cns   = cns.index.map(lambda f: int(f.replace('fCN','').replace('_1','')))\n",
    "    effstorms = []\n",
    "    for cn, f in zip(cns, farea):\n",
    "        cn = CN_correction(cn, basin_params.moisturecondition_1)\n",
    "        x = effective_storms(dhyeto.pr, method='SCS', CN=cn)*f\n",
    "        effstorms.append(x)\n",
    "    effstorms = sum(effstorms)\n",
    "    dhyeto  = effstorms.copy()\n",
    "    \n",
    "    # Compute flood hydrograph\n",
    "    runoff = xr.apply_ufunc(sg.convolve, dhyeto.pr_eff.fillna(0), uh.fillna(0),\n",
    "                input_core_dims=[['time'],['time']],\n",
    "                output_core_dims=[['time'],],\n",
    "                exclude_dims=set([('time'),]),\n",
    "                keep_attrs=True,\n",
    "                vectorize=True)\n",
    "    # runoff = runoff.where(runoff>0)\n",
    "    runoff.name = 'runoff'\n",
    "    runoff.coords['time'] = runoff.time*tstep\n",
    "    runoff.attrs = {'standard_name':'runoff', 'units':'m3*s1'}\n",
    "    \n",
    "    model = xr.merge([dhyeto, uh, runoff])\n",
    "    model.attrs = basin_params.to_dict()\n",
    "    model.attrs['timestep'] = tstep\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.31 s\n",
      "Wall time: 3.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "# ------------------------------ load parameters ----------------------------- #\n",
    "basin_params, storm_params, tstep = parse_params('data/params.csv',\n",
    "                                                 'data/synthethic_storms.csv')\n",
    "basin_params = basin_params.T\n",
    "basin_params['zone'] = ['I']*len(basin_params.index)\n",
    "basin_params = basin_params.T\n",
    "# Iterate over basins and run model\n",
    "models = {key:None for key in basin_params.columns}\n",
    "for fid in tqdm.tqdm(basin_params.columns, total=len(basin_params.columns)):\n",
    "    name = basin_params[fid].loc['name'].replace(' ','')\n",
    "    sim  = BasinFloodHydrograph(tstep, basin_params[fid], storm_params[fid])\n",
    "    models[fid] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fid in models.keys():\n",
    "    name = basin_params[fid].loc['name'].replace(' ','')\n",
    "    if not os.path.isdir(f'data/Basins/{name}'):\n",
    "        os.mkdir(f'data/Basins/{name}')\n",
    "        os.mkdir(f'data/Basins/{name}/tmp')\n",
    "        # time.sleep(0.1)\n",
    "    \n",
    "    models[fid].load().to_netcdf(f'data/Basins/{name}/tmp/SDH-Run_{name}.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riverine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
